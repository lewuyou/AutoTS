{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive # 挂载谷歌云盘\n",
    "# drive.mount('/content/drive')\n",
    "# !nvidia-smi # 显示显卡信息\n",
    "# ''' 符号%代表一直生效，！代表执行完立马结束，不会生效，所以进入目录用% '''\n",
    "# %cd /content/drive/MyDrive/timeSerise\n",
    "# ''' 支持的 常用命令1.ls  2.wget  3.gdoint(int(int(int(w))))n  4.mkdir  5.pwd '''\n",
    "# !ls\n",
    "# !pip install pyti\n",
    "# !pip install akshare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_provider.data_creat import *\n",
    "import akshare as ak\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    '''数据获取'''\n",
    "    fuquan = 'hfq'# 设置复权方式,adjust=空选择的不复权，qfq是前复权，应该用hfq后复权来进行量化分析\n",
    "    period = 'daily' # 拉取时间周期{'daily', 'weekly', 'monthly'}\n",
    "    start_date = '20151201'  # 20151201   20221021  下载数据的开始日期,1就是公司上市时间\n",
    "    end_date = '20231220'  # 下载数据的结束日期,如果1则到最后一天,如果-1是昨天.\n",
    "    start_date_time = pd.to_datetime('2015-12-01')\n",
    "    end_date_time = pd.to_datetime('2023-12-20')\n",
    "    label_n = 5 # 预测未来连续多少天的收益率\n",
    "    root_path = './dataset/'\n",
    "    air_data = 'shanghai-air-quality.csv' # 空气质量数据\n",
    "    # air_key = \"f75cec5c59f7abf51b27ab6433ba4d7637fa2153\"\n",
    "    national_debt = '中国十年期国债收益率历史数据.csv' # 国债数据\n",
    "    USD_exchange_rate = 'USD_CNH历史数据.csv' # 美元人民币汇率\n",
    "    HK_HSI = '香港恒生指数历史数据.csv'\n",
    "    \n",
    "    # 预测目标y是否替换成1或者0\n",
    "    zhangfu = 0.10  # 预测涨幅大于等于3%的为1，小于3%的为0\n",
    "    label_ch = True  # 如果是True ，预测n天以后上涨大于变量zhangfu为1，小于为0\n",
    "\n",
    "    # 是否合并全部股票数据\n",
    "    all = False\n",
    "    data_addzero = 60 # 当all = True时，用于训练的数据集分割，前面补0的长度\n",
    "    \n",
    "    # 数据修剪\n",
    "    start = 103 # 删除前24行（start=25），因为macd算不出来\n",
    "    end = 0 # (end = label_n if all else 0)删除最后部分需要预测天数label_n的数据，算出来是0.如果单只股票预测，那么不需要删除\n",
    "    final_data_feat =  ['index', 'Volume','Tom_Chg'] # 删除不需要列的标签\n",
    "\n",
    "# 创建参数对象\n",
    "args = Args()\n",
    "dataset_lists = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "空气数据数据读取中\n"
     ]
    }
   ],
   "source": [
    "# 获取上海空气数据\n",
    "if args.air_data:\n",
    "    print(\"空气数据数据读取中\")\n",
    "    # https://aqicn.org/historical/#city:shanghai\n",
    "    air_df = pd.read_csv(args.root_path + args.air_data)\n",
    "    air_df.columns = ['date', 'air_pm25', 'air_pm10', 'air_o3', 'air_no2', 'air_so2', 'air_co']\n",
    "    # 转换为时间格式、设置时间为索引、去除时区信息\n",
    "    air_df['date'] = pd.to_datetime(air_df['date'], errors='coerce')\n",
    "    air_df = air_df.set_index('date')\n",
    "    air_df = air_df.tz_localize(None)\n",
    "    # 只保留air_pm25列\n",
    "    air_df = air_df[['air_pm25']]\n",
    "    # 截取时间范围的数据\n",
    "    filtered_air_df = air_df[(air_df.index >= args.start_date_time) & (air_df.index <= args.end_date_time)]\n",
    "    dataset_lists.append(filtered_air_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "国债数据读取中\n"
     ]
    }
   ],
   "source": [
    "# 获取国债数据\n",
    "if args.national_debt:\n",
    "    print(\"国债数据读取中\")\n",
    "    # https://cn.investing.com/rates-bonds/china-10-year-bond-yield-historical-data?dt_dapp=1\n",
    "    national_debt_df = pd.read_csv(args.root_path + args.national_debt)\n",
    "    # 重命名列名\n",
    "    national_debt_df.columns = ['date', 'national_close', 'national_open', 'national_high', 'national_low', 'national_change']\n",
    "    national_debt_df['date'] = pd.to_datetime(national_debt_df['date'], errors='coerce')\n",
    "    national_debt_df = national_debt_df.set_index('date')\n",
    "    national_debt_df = national_debt_df.tz_localize(None)\n",
    "    # 只保留'national_close'列\n",
    "    national_debt_df = national_debt_df[['national_close']]\n",
    "    filtered_national_debt_df = national_debt_df[(national_debt_df.index >= args.start_date_time) & (national_debt_df.index <= args.end_date_time)]\n",
    "    dataset_lists.append(filtered_national_debt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "人民币汇率数据读取中\n"
     ]
    }
   ],
   "source": [
    "# 获取人民币汇率\n",
    "if args.USD_exchange_rate:\n",
    "    print(\"人民币汇率数据读取中\")\n",
    "    # https://cn.investing.com/currencies/usd-cnh-historical-data\n",
    "    USD_exchange_rate_df = pd.read_csv(args.root_path + args.USD_exchange_rate)\n",
    "    USD_exchange_rate_df.columns = ['date', 'USD_close', 'USD_open', 'USD_high', 'USD_low', 'USD_volume', 'USD_change']\n",
    "    USD_exchange_rate_df['date'] = pd.to_datetime(USD_exchange_rate_df['date'], errors='coerce')\n",
    "    USD_exchange_rate_df = USD_exchange_rate_df.set_index('date')\n",
    "    USD_exchange_rate_df = USD_exchange_rate_df.tz_localize(None)\n",
    "    # 只保留'USD_close'列\n",
    "    USD_exchange_rate_df = USD_exchange_rate_df[['USD_close']]\n",
    "    filtered_USD_exchange_rate_df = USD_exchange_rate_df[(USD_exchange_rate_df.index >= args.start_date_time) & (USD_exchange_rate_df.index <= args.end_date_time)]\n",
    "    dataset_lists.append(filtered_USD_exchange_rate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "香港恒生指数数据读取中\n"
     ]
    }
   ],
   "source": [
    "# 获取香港恒生指数\n",
    "if args.HK_HSI:\n",
    "    print(\"香港恒生指数数据读取中\")\n",
    "    # https://cn.investing.com/indices/hang-sen-40-historical-data\n",
    "    HK_HSI_df = pd.read_csv(args.root_path + args.HK_HSI)\n",
    "    HK_HSI_df.columns = ['date', 'HK_HSI_close', 'HK_HSI_open', 'HK_HSI_high', 'HK_HSI_low', 'HK_HSI_volume', 'HK_HSI_change']\n",
    "    HK_HSI_df['date'] = pd.to_datetime(HK_HSI_df['date'], errors='coerce')\n",
    "    HK_HSI_df = HK_HSI_df.set_index('date')\n",
    "    HK_HSI_df = HK_HSI_df.tz_localize(None)\n",
    "    # 只保留'HK_HSI_close'列\n",
    "    HK_HSI_df = HK_HSI_df[['HK_HSI_close']]\n",
    "    # 转换所有列为数值，移除逗号\n",
    "    for column in HK_HSI_df.columns:\n",
    "        HK_HSI_df[column] = HK_HSI_df[column].str.replace(',', '').astype(float)/1000\n",
    "    # 过滤数据\n",
    "    filtered_HK_HSI_df = HK_HSI_df[(HK_HSI_df.index >= args.start_date_time) & (HK_HSI_df.index <= args.end_date_time)]\n",
    "    dataset_lists.append(filtered_HK_HSI_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            HK_HSI_close\n",
      "date                    \n",
      "2023-12-20      16.61381\n",
      "2023-12-19      16.50500\n",
      "2023-12-18      16.62923\n",
      "2023-12-15      16.79219\n",
      "2023-12-14      16.40219\n",
      "...                  ...\n",
      "2015-12-07      22.20322\n",
      "2015-12-04      22.23589\n",
      "2015-12-03      22.41701\n",
      "2015-12-02      22.47969\n",
      "2015-12-01      22.38135\n",
      "\n",
      "[1988 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataset_lists[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建股票数据列表\n",
    "stock_down = ak.stock_cy_a_spot_em() # 创业板实时数据\n",
    "stock_list = stock_down[~stock_down['名称'].str.contains(\"退|ST\") & (stock_down['流通市值'] <= 1e11) & (stock_down['总市值'] >= 45e8)] # 去除退市和ST股票\n",
    "file_name_cy = 'Stock_list_cy.csv'# 保存数据，编码格式为utf-8\n",
    "stock_list.to_csv(args.root_path + file_name_cy,index=False,encoding='utf-8-sig')\n",
    "\n",
    "# 读取股票列表\n",
    "stock_list = pd.read_csv(args.root_path + file_name_cy) # 读取股票列表\n",
    "# 将股票代码的数字转换为字符串列表\n",
    "stock_list = [str(code) for code in stock_list['代码'].tolist()]\n",
    "\n",
    "stock_list = ['600028'] # 自定义股票列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "获取数据时间为： 20151201 - 20231220\n",
      "原始数据形状： (1961, 9)\n",
      "添加数据以后形状： (1961, 33)\n",
      "删除指定行、列后数据形状:  (1858, 32)\n",
      "股票代码 600028 的数据保存完毕，形状: (1858, 32)\n",
      "处理进度: 1/1 (100.00%)\n",
      "单独数据保存完毕。\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "all_data_raw = pd.DataFrame()  # 初始化一个空的 DataFrame 用于存储原始数据\n",
    "all_data_scaled = pd.DataFrame()  # 初始化一个空的 DataFrame 用于存储标准化后的数据\n",
    "processed_count = 0  # 初始化计数器\n",
    "total_count = len(stock_list)  # 获取总股票数量\n",
    "scaler = StandardScaler()\n",
    "\n",
    "for i in stock_list[:]:\n",
    "    NUM = i\n",
    "    try:\n",
    "        # 下载原始数据\n",
    "        raw_data = download_data(NUM, args)\n",
    "        # 更新已处理股票数量计数器\n",
    "        processed_count += 1\n",
    "        # 检查数据长度，如果小于300则跳过此次循环\n",
    "        if raw_data.shape[0] < 280:\n",
    "            print(f\"股票代码 {NUM} 的数据长度小于300,跳过此次循环。\")\n",
    "            continue\n",
    "        \n",
    "        # 拼接数据，添加各种参数\n",
    "        ad_data = add_data(raw_data, args)\n",
    "        # 添加预测标签\n",
    "        # ad_data = add_label(ad_data, args)\n",
    "        # 删除无效数据\n",
    "        final_data_raw = sub_data(ad_data.copy(), args)\n",
    "        final_data_scaled = final_data_raw.copy()\n",
    "        \n",
    "        # 未处理数据的前20行替换为0\n",
    "        if args.data_addzero and not all_data_raw.empty:\n",
    "            final_data_raw = add_zeros_to_data(final_data_raw, num_rows=args.data_addzero)\n",
    "\n",
    "        # 标准化处理\n",
    "        non_time_columns = final_data_scaled.columns[1:-1]  # 假设时间列是第一列\n",
    "        final_data_scaled[non_time_columns] = scaler.fit_transform(final_data_scaled[non_time_columns])\n",
    "\n",
    "        # 标准化处理的数据的前20行替换为0\n",
    "        if args.data_addzero and not all_data_scaled.empty:\n",
    "            final_data_scaled = add_zeros_to_data(final_data_scaled, num_rows=args.data_addzero)\n",
    "        \n",
    "        # 如果 all 为 False, 则为每个股票单独保存数据\n",
    "        if not args.all:\n",
    "            file_name_raw_individual = f\"raw_stock_cy_{NUM}.csv\"\n",
    "            file_name_scaled_individual = f\"scaled_stock_cy_{NUM}.csv\"\n",
    "            final_data_raw.to_csv(args.root_path + file_name_raw_individual, index=False)\n",
    "            final_data_scaled.to_csv(args.root_path + file_name_scaled_individual, index=False)\n",
    "            print(f\"股票代码 {NUM} 的数据保存完毕，形状: {final_data_raw.shape}\")\n",
    "        else:\n",
    "            # 拼接未处理的数据\n",
    "            all_data_raw = pd.concat([all_data_raw, final_data_raw], ignore_index=True)\n",
    "            # 拼接经过标准化的数据\n",
    "            all_data_scaled = pd.concat([all_data_scaled, final_data_scaled], ignore_index=True)\n",
    "            print(f\"当前all_data的形状: {all_data_scaled.shape}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"处理股票代码 {NUM} 时出现错误: {e}\")\n",
    "        continue\n",
    "\n",
    "    # 计算并打印处理进度\n",
    "    progress = processed_count / total_count\n",
    "    print(f\"处理进度: {processed_count}/{total_count} ({progress:.2%})\")\n",
    "\n",
    "# 如果 all 为 True, 则保存合并后的数据\n",
    "if args.all:\n",
    "    time = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "    file_name_raw = \"stock_cy_all_raw.csv\"\n",
    "    file_name_scaled = \"stock_cy_all_scaled.csv\"\n",
    "    all_data_raw.to_csv(args.root_path + time + file_name_raw, index=False)\n",
    "    all_data_scaled.to_csv(args.root_path + time + file_name_scaled, index=False)\n",
    "    print(\"合并数据保存完毕。\")\n",
    "else:\n",
    "    print(\"单独数据保存完毕。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
